{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp Census_Bureau_urban_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://www2.census.gov/geo/pdfs/reference/GARM/Ch12GARM.pdf:\n",
    "\n",
    "# \"Urbanized Areas (UAs)\n",
    "# A UA is a continuously built-up area with a population of 50,000 or more.\n",
    "# It comprises one or more places—central place(s)—and the adjacent densely settled surrounding \n",
    "# area—urban fringe—consisting of other places and nonplace territory.\"\n",
    "\n",
    "# \"Urban Places Outside of UAs\n",
    "# Outside of UAs, an urban place is any incorporated place or census designated place (CDP) with \n",
    "# at least 2,500 inhabitants. A CDP is a densely settled population center that has a name and \n",
    "# community identity, and is not part of any incorporated place.\"\n",
    "\n",
    "# \"Rural Places and Territory\n",
    "# Territory, population, and housing units that the Census Bureau does not classify as urban are classified \n",
    "# as rural.\"\n",
    "\n",
    "# Census Urban Areas and Urban Clusters are not based on political boundaries at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 11.4 s, total: 1min 29s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# (Takes about 1.25 clock minutes.)\n",
    "year = 2017\n",
    "infile = 'data/df_%d_OMB.csv' % year\n",
    "df = pd.read_csv(infile)\n",
    "\n",
    "df['CBSA Code'] = df['CBSA Code'].fillna(99999)\n",
    "df['CBSA Code'] = df['CBSA Code'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use a df copy instead of reading it in again. Uncomment the useful line.\n",
    "#df_copy = df.copy()\n",
    "#df = df_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "883453\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(df[df['CBSA Code']==0]))\n",
    "print(len(df[df['CBSA Code']==99999]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "935"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['CBSA Code'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Urban Area (UA) to each row by matching InfoGroup 'CBSA Code' (metro/micropolitan area) to the Census\n",
    "# Relationship file that cross-references CBSA and UA.\n",
    "relationship = 'Relationship_Files/Urban_Area_to_Metro_Micro_Area_utf-8.csv'\n",
    "rel = pd.read_csv(relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955\n",
      "3601\n"
     ]
    }
   ],
   "source": [
    "cbsa_list = rel['CBSA'].drop_duplicates().tolist()\n",
    "ua_list = rel['UA'].drop_duplicates().tolist()\n",
    "cbsa_list.remove(99999)\n",
    "ua_list.remove(99999)\n",
    "print(len(cbsa_list))\n",
    "print(len(ua_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5167\n",
      "5167 \n",
      "\n",
      "1038\n",
      "4129 \n",
      "\n",
      "955\n",
      "4212 \n",
      "\n",
      "3174\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# The file contains a record for all metro/micro areas (CBSAs) and all urban areas/clusters (UAs) in 2010.\n",
    "# Exploration:\n",
    "print(len(rel))\n",
    "print(len(rel[['UA','CBSA']].drop_duplicates()), '\\n')\n",
    "# There are 5167 records in the file, all with paired values of UA and CBSA that are unique.\n",
    "\n",
    "print(len(rel[['UA','CBSA']][rel['CBSA']==99999]))\n",
    "print(len(rel[['UA','CBSA']][rel['CBSA']!=99999]),'\\n')\n",
    "# There are 1038 records with a valid UA code but NO metro/micro area (CBSA).\n",
    "# There are 4129 UAs with a valid CBSA.\n",
    "\n",
    "print(len(rel[['UA','CBSA']][rel['UA']==99999]))\n",
    "print(len(rel[['UA','CBSA']][rel['UA']!=99999]),'\\n')\n",
    "# There are 955 records with a valid CBSA code but NO urban area/cluster (UA).\n",
    "# There are 4212 CBSAs with a valid UA.\n",
    "\n",
    "print(len(rel[(rel['CBSA']!=99999) & (rel['UA']!=99999)]))\n",
    "# There are 3174 records with valid unique combinations of the CBSA and UA values.\n",
    "\n",
    "print(len(rel[(rel['CBSA']==99999) & (rel['UA']==99999)]))\n",
    "# By definition there are no cases in which both the CBSA and UA are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "956\n",
      "3602\n"
     ]
    }
   ],
   "source": [
    "print(len(rel['CBSA'].drop_duplicates()))\n",
    "print(len(rel['UA'].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above means that on the average there are is least a part of more than 3 UA's for each CBSA. Thus the\n",
    "# only way to get a one-to-one mapping of CBSA to UA will be to do the shapely 'within' comparison; determine\n",
    "# whether the point coordinates of an IG enterprise fall within the polygon coordinates of a particular UA.\n",
    "\n",
    "# But to create a simple 'rural_Census' flag we need only to discover whether the CBSA Code of the IG record\n",
    "# matches any CBSA code in the relationship file that is not in an urban area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is a UA in a CBSA 1) partly, 2) entirely, or 3) not at all?\n",
    "# Make a dict with the UA as the key and the value a list of all CBSA codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The uas dict has a list of CBSAs for each UA. The ua_keys dict tags each UA as rural, partly rural, or\n",
    "# urban. But in InfoGroup we have only CBSA Code. We can determine if the IG record's CBSA Code matches to a UA that \n",
    "# is entirely urban and that is completely within the CBSA; i.e., it has only the IG record's CBS code in its\n",
    "# CBSA list. And if it matches to a UA that is entirely rural; i.e., the UA has only a single 99999 in its CBSA list.\n",
    "\n",
    "# The cbsas dict is a reverse version of uas: a key for every CBSA and, as the value, the list of UAs associated\n",
    "# with the key. The cbsas_keys dict substitutes the urban/rural tag of each UA for its code value. Using those \n",
    "# lists of text values we can determine whethera record is rural, partly rural, or urban."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UA key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict from list of lists.\n",
    "uas = {}\n",
    "for l in rel[['UA','CBSA']].values.tolist():\n",
    "    try:\n",
    "        uas[l[0]].append(l[1])\n",
    "    except:\n",
    "        uas[l[0]] = [l[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1038\n"
     ]
    }
   ],
   "source": [
    "# Validate that 99999 can occur only once in any value list in the uas dict.\n",
    "n = 0\n",
    "m = 0\n",
    "for k,v in uas.items():\n",
    "    if v.count(99999) > 1:\n",
    "        n += 1\n",
    "    elif v.count(99999) == 1:\n",
    "        m += 1\n",
    "        \n",
    "print(n,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize all the UAs as urban, rural, partly rural, or unknown.\n",
    "# Partly rural == UA with some valid CBSAs and at least 1 99999;\n",
    "# Rural (entirely rural) == UA with no valid CBSAs, just some 99999s;\n",
    "# Urban (not at all rural) == UA with some valid CBSAs but no 99999s.\n",
    "# Unknown == UA 99999 (missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_nines(li):\n",
    "    length = len(li)\n",
    "    n = 0\n",
    "    for item in li:\n",
    "        if item == 99999:\n",
    "            n += 1\n",
    "    if n == length:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua_keys = dict.fromkeys(uas.keys())\n",
    "for k,v in uas.items():\n",
    "    if len(v) > 1:\n",
    "        if all_nines(v):\n",
    "            ua_keys[k] = 'rural-multi'\n",
    "        elif 99999 in v:\n",
    "            ua_keys[k] = 'partly rural'\n",
    "        elif k == 99999:\n",
    "            ua_keys[k] = 'unknown'\n",
    "        else:\n",
    "            ua_keys[k]= 'urban-multi'\n",
    "    else:\n",
    "        if v[0] == 99999:\n",
    "            ua_keys[k] = 'rural-single'\n",
    "        else:\n",
    "            ua_keys[k] = 'urban-single'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown\n"
     ]
    }
   ],
   "source": [
    "# Validate that all keys have values [and remove the key for UA 99999].\n",
    "for i,v in ua_keys.items():\n",
    "    if v == None: \n",
    "        print(i)\n",
    "print(ua_keys[99999])\n",
    "\n",
    "# No, don't delete the key for 99999\n",
    "#del ua_keys[99999]\n",
    "#try:\n",
    "#    print(ua_keys[99999])\n",
    "#except KeyError:\n",
    "#    print('No such key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 3602 UAs: \n",
      " 908 are entirely rural, \n",
      " 130 are partly rural, \n",
      " 2563 are urban, and \n",
      " 1 is unknown.\n"
     ]
    }
   ],
   "source": [
    "len_att = len(ua_keys)\n",
    "entire = 0\n",
    "urban = 0\n",
    "part = 0\n",
    "unk = 0\n",
    "for k,v in ua_keys.items():\n",
    "    if v in ['rural-single','rural-multi']:\n",
    "        entire += 1\n",
    "    elif v == 'partly rural':\n",
    "        part += 1\n",
    "    elif v in ['urban-single','urban-multi']:\n",
    "        urban += 1\n",
    "    elif v == 'unknown':\n",
    "        unk += 1\n",
    "\n",
    "print('Out of',str(len_att),'UAs:','\\n',str(entire),'are entirely rural,','\\n',str(part),'are partly rural,','\\n',\n",
    "      str(urban),'are urban, and','\\n',str(unk),'is unknown.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.15491393670183\n",
      "25.2082176568573\n",
      "3.6091060521932263\n",
      "0.027762354247640203\n"
     ]
    }
   ],
   "source": [
    "print(str((2563/3602)*100))\n",
    "print(str((908/3602)*100))\n",
    "print(str((130/3602)*100))\n",
    "print(str((1/3602)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBSA key\n",
    "# a CBSA is not covered entirely by UAs, so is it valid to assess the rurality of a record if it only has a\n",
    "# CBSA Code and no way to categorize the parts of the CBSA that are not covered by any UA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict from list of lists.\n",
    "cbsas = {}\n",
    "for l in rel[['UA','CBSA']].values.tolist():\n",
    "    try:\n",
    "        cbsas[l[1]].append(l[0])\n",
    "    except:\n",
    "        cbsas[l[1]] = [l[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove all occurrences of a particular value from a list.\n",
    "def remove_all(li,val):\n",
    "    i = 0\n",
    "    while i < len(li):\n",
    "        try:\n",
    "            li.remove(val)\n",
    "        except:\n",
    "            pass\n",
    "        i += 1\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cbsas[99999]\n",
    "for k,v in cbsas.items():\n",
    "    cbsas[k] = remove_all(v,99999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "955"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cbsas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the list of UAs that are associated with a single CBSA code.\n",
    "def find_uas(cbsa): \n",
    "    uas_list = []\n",
    "    for k in uas.keys():\n",
    "        #if k == 99999: \n",
    "            #continue\n",
    "        if cbsa in uas[k]:\n",
    "            uas_list.append(k)\n",
    "    return uas_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the urban/rural descriptions for each UA in a list of UAs.\n",
    "def find_descs(uas_list):\n",
    "    descs_list = []\n",
    "    for ua in uas_list:\n",
    "        descs_list.append(ua_keys[ua])\n",
    "    return descs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object:\n",
    "#       cbsa_keys: a dict with CBSA codes as keys and empty lists to be filled in with urban/rural text strings as values.\n",
    "\n",
    "cbsa_keys = dict.fromkeys(cbsas.keys())\n",
    "\n",
    "# Data: \n",
    "#       uas: a dict with UA codes as keys and lists of constituent CBSAs as values.\n",
    "#       uas_keys: a dict with UA codes as keys and one of 'rural','partly rural', and 'urban' as a value.\n",
    "#       cbsas: a dict with CBSA values as keys and lists of constituent UAs as values.\n",
    "\n",
    "for cbsa in cbsa_keys.keys():\n",
    "    li = find_uas(cbsa)\n",
    "    cbsa_keys[cbsa] = find_descs(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37, 43993, 46045]\n",
      "['urban-multi', 'urban-single', 'urban-multi', 'unknown']\n",
      "urban-multi urban-single urban-multi unknown\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "print(cbsas[10020])\n",
    "print(cbsa_keys[10020])\n",
    "print(ua_keys[37],ua_keys[43993],ua_keys[46045],ua_keys[99999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91, 55144, 93025]\n",
      "['partly rural', 'urban-multi', 'urban-single', 'unknown']\n",
      "partly rural urban-multi urban-single unknown\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "print(cbsas[48140])\n",
    "print(cbsa_keys[48140])\n",
    "print(ua_keys[91],ua_keys[55144],ua_keys[93025],ua_keys[99999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add an 'invalid_rural_Census' variable with appropriate values(?). Invalid because the logic is\n",
    "# faulty, as it turns out. For example...\n",
    "# If one description is 'partly rural', the whole CBSA is partly rural\n",
    "# If there is a mixture of urban and rural (and partly rural), the whole CBSA is partly rural\n",
    "# Otherwise, rural and urban are both all rural or all urban\n",
    "def assign_text(code):\n",
    "    try:\n",
    "        li = cbsa_keys[code]\n",
    "    except KeyError:\n",
    "        return 'not available'\n",
    "    \n",
    "    if 'partly rural' in li:\n",
    "        return 'partly rural'\n",
    "    elif 'urban' in li and 'rural' in li:\n",
    "        return 'partly rural'\n",
    "    elif 'rural' in li:\n",
    "        return 'rural'\n",
    "    elif 'urban' in li:\n",
    "        return 'urban'\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['invalid_rural_Census'] = df['CBSA Code'].apply(assign_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown          10099729\n",
       "partly rural      2942686\n",
       "not available     1691022\n",
       "Name: invalid_rural_Census, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['invalid_rural_Census'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown          68.549715\n",
       "partly rural     19.972841\n",
       "not available    11.477444\n",
       "Name: invalid_rural_Census, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['invalid_rural_Census'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No cases in which all UAs for a CBSA are rural?\n",
    "n = 0\n",
    "for i,v in cbsa_keys.items():\n",
    "    if v.count('rural') == len(v):\n",
    "        n += 1\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Are all the 'not availables' KeyErrors? Yes.\n",
    "unknowns = set([i for i in df['CBSA Code'][df['invalid_rural_Census']=='not available']])\n",
    "print(len(unknowns))\n",
    "\n",
    "n = 0\n",
    "master = set(cbsas.keys())\n",
    "for unk in unknowns:\n",
    "    if unk in master:\n",
    "        n += 1\n",
    "print(n)\n",
    "\n",
    "# Thus 53 CBSA Codes in the InfoGroup file are not listed in the relationship file. These are the CBSA Code\n",
    "# values for 1,691,022 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple 'reverse-rurality' indicator: for each CBSA in the InfoGroup file, does it match to any CBSA in the \n",
    "# relationship file that is matched there to a valid UA code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5167\n",
      "3174\n",
      "955\n"
     ]
    }
   ],
   "source": [
    "pairs = rel[['UA','CBSA']].values.tolist()\n",
    "print(len(pairs))\n",
    "urban_cbsas = []\n",
    "for pair in pairs:\n",
    "    if pair[0] == 99999 or pair[1] == 99999:\n",
    "        continue\n",
    "    else:\n",
    "        urban_cbsas.append(pair[1])\n",
    "print(len(urban_cbsas))\n",
    "urban_cbsas_set = set(urban_cbsas)\n",
    "print(len(urban_cbsas_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isit_rural(code):\n",
    "    if code in urban_cbsas_set:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rural_Census_general'] = df['CBSA Code'].apply(isit_rural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    13042415\n",
      "1     1691022\n",
      "Name: rural_Census_general, dtype: int64\n",
      "0    88.522556\n",
      "1    11.477444\n",
      "Name: rural_Census_general, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['rural_Census_general'].value_counts())\n",
    "print(df['rural_Census_general'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('invalid_rural_Census',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For later analysis we will want the six-digit NAICS codes as well as the 8-digit code that comes with\n",
    "# InfoGroup and the 2-digit code and description that we created in the #1 notebook.\n",
    "# We'll also include some descriptions for some codes that the project statement mentions specifically as\n",
    "# definitely agricultural.\n",
    "\n",
    "df['NAICS6'] = df['Primary NAICS Code'].apply(lambda x: str(x)[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_naics = {'112112':'Cattle Feedlots',\n",
    "            '115111':'Cotton Ginning',\n",
    "            '115112':'Soil Preparation, Planting and Cultivating',\n",
    "            '115113':'Crop Harvesting, Primarily by Machine',\n",
    "            '115114':'Postharvest Crop Activities except Cotton Ginning',\n",
    "            '115115':'Farm Labor Contractors and Crew Leaders',\n",
    "            '115116':'Farm Management Services',\n",
    "            '423820':'Farm and Garden Machinery and Equipment Merchant Wholesalers',\n",
    "            '424430':'Dairy Product Merchant Wholesalers',\n",
    "            '424440':'Poultry and Poultry Product Merchant Wholesalers',\n",
    "            '424480':'Fresh Fruit and Vegetable Merchant Wholesalers',\n",
    "            '424510':'Grain and Field Bean Merchant Wholesalers',\n",
    "            '424520':'Livestock Merchant Wholesalers',\n",
    "            '424590':'Other Farm Product Raw Material Merchant Wholesalers',\n",
    "            '424910':'Farm Supplies Merchant Wholesalers',\n",
    "            '493130':'Farm Product Warehousing and Storage'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naics6_desc(code):\n",
    "    if code in ag_naics.keys():\n",
    "        return ag_naics[code]\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NAICS6 desc'] = df['NAICS6'].apply(naics6_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Farm Supplies Merchant Wholesalers                              18210\n",
       "Farm and Garden Machinery and Equipment Merchant Wholesalers    11859\n",
       "Farm Product Warehousing and Storage                             4356\n",
       "Fresh Fruit and Vegetable Merchant Wholesalers                   3829\n",
       "Farm Management Services                                         2353\n",
       "Livestock Merchant Wholesalers                                   2199\n",
       "Dairy Product Merchant Wholesalers                               1276\n",
       "Soil Preparation, Planting and Cultivating                       1211\n",
       "Grain and Field Bean Merchant Wholesalers                        1119\n",
       "Cattle Feedlots                                                  1063\n",
       "Postharvest Crop Activities except Cotton Ginning                 669\n",
       "Other Farm Product Raw Material Merchant Wholesalers              649\n",
       "Poultry and Poultry Product Merchant Wholesalers                  623\n",
       "Cotton Ginning                                                    428\n",
       "Farm Labor Contractors and Crew Leaders                           255\n",
       "Crop Harvesting, Primarily by Machine                             183\n",
       "Name: NAICS6 desc, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['NAICS6 desc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14683155"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['NAICS6 desc'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company', 'Address Line 1', 'City', 'State', 'ZipCode', 'County Code',\n",
       "       'Primary SIC Code', 'SIC6_Descriptions', 'Primary NAICS Code',\n",
       "       'NAICS8 Descriptions', 'Employee Size (5) - Location',\n",
       "       'Sales Volume (9) - Location', 'Business Status Code',\n",
       "       'Industry Specific First Byte', 'Year Established', 'ABI',\n",
       "       'Subsidiary Number', 'Parent Number', 'Parent Actual Employee Size',\n",
       "       'Parent Actual Sales Volume', 'Census Tract', 'Census Block',\n",
       "       'Latitude', 'Longitude', 'CBSA Code', 'CBSA Level', 'FIPS Code',\n",
       "       'State FIPS', 'Continental', 'NAICS2', 'NAICS2 desc', 'CBSA Level desc',\n",
       "       'rural_OMB', 'rural_Census_general', 'NAICS6', 'NAICS6 desc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "outfile = 'data/df_%d_OMB_Census_TEMP.csv' % year\n",
    "df.to_csv(outfile,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to do the point-in-polygon comparison..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "year = 2017\n",
    "infile = 'data/df_%d_OMB_Census_TEMP.csv' % year\n",
    "df = pd.read_csv(infile,dtype=object)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df[['Latitude','Longitude']] = df[['Latitude','Longitude']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfx = df[['ABI','Latitude','Longitude']].sample(n=10000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def pointer(lon,lat):\n",
    "    return Point(lon,lat)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "dfx['geometry'] = dfx.apply(lambda x: pointer(x['Longitude'], x['Latitude']), axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfx.drop(columns=['Latitude','Longitude'],inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The 2010 Urban Area to Metropolitan and Micropolitan Statistical Areas Relationship File provides relationships between the 2010 urban areas and the Metro and Micro Areas. Urban areas include both urbanized areas (UA) and urban clusters (UC), and areas outside urban areas are considered rural. \n",
    "\n",
    "This list can be utilized to see if a metro or micro area is urban, rural, or contains both urban and rural area.\n",
    "\n",
    "Each record in the relationship file represents one polygon that is formed when the 2010 urban areas overlay the metro and micro areas. The polygon may represent the intersection of a 2010 urban area and a metro or micro area, or the portion of the metro or micro area that does not contain a 2010 urban area. In addition, since metro and micro areas are not a wall-to-wall coverage across the U.S., the polygon may represent the area of a 2010 urban area that does not intersect a metro and micro area."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The polygons of the UAs.\n",
    "shape = 'map_files/tl_2017_us_uac10.shp'\n",
    "ua = gpd.read_file(shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#ua.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ua.set_index(\"UACE10\", inplace = True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ua_dict = dict.fromkeys(ua.index)\n",
    "for k in ua_dict.keys():\n",
    "    ua_dict[k] = ua.loc[k]['geometry']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def set_ua(pnt):\n",
    "    for k,p in ua_dict.items():\n",
    "        if pnt.within(p):\n",
    "            return k\n",
    "    return '99999'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "dfx['UA'] = dfx.apply(lambda row: set_ua(row['geometry']),axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# vectorized execution of a function that takes 4 params. faster than .apply()\n",
    "#df['distance'] = haversine(40.671, -73.985, df['latitude'], df['longitude'])\n",
    "# even better: use numpy arrays produced under the hood by .values\n",
    "#df['distance'] = haversine(40.671, -73.985, df['latitude'].values, df['longitude'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 15 programs in the points-in-polygons folder ran simultaneously as a brute force method of parallel \n",
    "# processing to locate the InfoGroup points in UA polygons. They incorporate the logic, maybe not the exact code,\n",
    "# of the non-executable cells just above. They produced 15 csv files with the UA code for\n",
    "# the UA record along with the shapely geometry and the ABI of the record.  Now combine those 15 files into \n",
    "# one and merge the result into the df dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14733437\n",
      "CPU times: user 1min 18s, sys: 4.93 s, total: 1min 22s\n",
      "Wall time: 29.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pp_df = pd.DataFrame()\n",
    "\n",
    "for seq in range(1,16):\n",
    "    infile = 'points-in-polygons/data/dfx_%d.csv' % seq\n",
    "    df_tmp = pd.read_csv(infile,dtype=object)\n",
    "    pp_df = pd.concat([pp_df,df_tmp])\n",
    "\n",
    "print(len(pp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_df['ABI'] = pp_df['ABI'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 26.3 s, total: 2min 14s\n",
      "Wall time: 1min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Company', 'Address Line 1', 'City', 'State', 'ZipCode', 'County Code',\n",
       "       'Primary SIC Code', 'SIC6_Descriptions', 'Primary NAICS Code',\n",
       "       'NAICS8 Descriptions', 'Employee Size (5) - Location',\n",
       "       'Sales Volume (9) - Location', 'Business Status Code',\n",
       "       'Industry Specific First Byte', 'Year Established', 'ABI',\n",
       "       'Subsidiary Number', 'Parent Number', 'Parent Actual Employee Size',\n",
       "       'Parent Actual Sales Volume', 'Census Tract', 'Census Block',\n",
       "       'Latitude', 'Longitude', 'CBSA Code', 'CBSA Level', 'FIPS Code',\n",
       "       'State FIPS', 'Continental', 'NAICS2', 'NAICS2 desc', 'CBSA Level desc',\n",
       "       'rural_OMB', 'rural_Census_general', 'NAICS6', 'NAICS6 desc',\n",
       "       'geometry', 'UA', '_merge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Merge with df\n",
    "df_final = df.merge(pp_df,on='ABI',how='inner',indicator=True)\n",
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "both          14733437\n",
       "right_only           0\n",
       "left_only            0\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The polygon 'geometry' is no longer necessary. Ditto for '_merge'.\n",
    "df_final.drop(columns=['geometry','_merge'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the definitive 'rural_Census' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rural percentage by the most specific Census-based standard 13.762579634337868\n"
     ]
    }
   ],
   "source": [
    "# Informational\n",
    "rural_pct = len(df_final[df_final['UA'] == '99999']) / len(df_final) * 100.0\n",
    "print('Rural percentage by the most specific Census-based standard',str(rural_pct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['rural_Census'] = df_final['UA'].apply(lambda x: 1 if x == '99999' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    86.23742\n",
       "1    13.76258\n",
       "Name: rural_Census, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['rural_Census'].value_counts(normalize=True) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the InfoGroup file we now have the Urban Area identifier. That can be merged with locational variables from \n",
    "# the Census shapefile for mapping. The output file here is a regular .csv file, not a shapefile, but it does have\n",
    "# identifiers and coordinates for each UA and can be read into a GeoDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company', 'Address Line 1', 'City', 'State', 'ZipCode', 'County Code',\n",
       "       'Primary SIC Code', 'SIC6_Descriptions', 'Primary NAICS Code',\n",
       "       'NAICS8 Descriptions', 'Employee Size (5) - Location',\n",
       "       'Sales Volume (9) - Location', 'Business Status Code',\n",
       "       'Industry Specific First Byte', 'Year Established', 'ABI',\n",
       "       'Subsidiary Number', 'Parent Number', 'Parent Actual Employee Size',\n",
       "       'Parent Actual Sales Volume', 'Census Tract', 'Census Block',\n",
       "       'Latitude', 'Longitude', 'CBSA Code', 'CBSA Level', 'FIPS Code',\n",
       "       'State FIPS', 'Continental', 'NAICS2', 'NAICS2 desc', 'CBSA Level desc',\n",
       "       'rural_OMB', 'rural_Census_general', 'NAICS6', 'NAICS6 desc', 'UA',\n",
       "       'rural_Census'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 54s, sys: 8.25 s, total: 10min 2s\n",
      "Wall time: 10min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outfile = 'data/df_%d_OMB_Census.csv' % year\n",
    "df_final.to_csv(outfile,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
