{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp frontier_and_remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although both the FAR dataset and the ZCTA-to-whatever relationship files both come from Census,\n",
    "# the zip code areas presented by FAR are from ESRI and are not entirely compatible with the ZCTA areas.\n",
    "# ESRI business location data come from InfoGroup. It isn't clear where the zip code data that FAR take\n",
    "# from ESRI are from, but they almost certainly are postal zip codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Wikipedia:\n",
    "# ZCTAs are generalized area representations of the United States Postal Service (USPS) ZIP code service areas, \n",
    "# but are not the same as ZIP codes. Individual USPS ZIP codes can cross state, place, county, census tract, \n",
    "# census block group and census block boundaries, so the Census Bureau asserts that \"there is no correlation \n",
    "# between ZIP codes and Census Bureau geography\".[1] Moreover, the USPS frequently realigns, merges, or splits \n",
    "# ZIP codes to meet changing needs. These changes are usually not reflected in the annual TIGER releases. \n",
    "# Each ZCTA is constructed by aggregating the Census 2010 blocks whose addresses use a given ZIP code. In \n",
    "# assembling census statistical units to create ZCTAs, the Census Bureau took the ZIP code used by the majority \n",
    "# of addresses in each census unit at the time the data was compiled. As a result, some addresses end up with a \n",
    "# ZCTA code that is different from their ZIP code. ZCTAs are not developed for ZIP codes that comprise only a \n",
    "# small number of addresses.[2] Several ZCTAs represent ZIPs that no longer exist due to realignment by the USPS.\n",
    "\n",
    "# There are approximately 42,000 ZIP Codes and 32,000 ZCTAs. The main reason that there is not one ZCTA for every \n",
    "# ZIP Code is that PO Boxes are excluded in ZCTAs, since only populated areas are included in the Census data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary: problems using zip code as an analytical unit.\n",
    "\n",
    "# Postal zip codes change to suit the Postal Services needs and those changes are not immediately reflected\n",
    "# in other data bases or in TIGER files.\n",
    "\n",
    "# ZCTA (standardized zipcode-based tablulation areas) units are not the same as postal zip codes, as described\n",
    "# above. \n",
    "\n",
    "# We do not know the source of InfoGroup's zip code data. It is probably self-identified by the enterprise and\n",
    "# therefore probably a postal zip code.\n",
    "\n",
    "# ZCTA relationship files do not include any relationship between ZCTAs and postal zip codes. \n",
    "\n",
    "# ESRI business location data comes from InfoGroup, which probably suggests that all their zip code data are\n",
    "# postal zip codes. So the zip codes in the FAR data should be compatible with our InfoGroup data, although not \n",
    "# aligned in time. The FAR data comes otherwise from the 2010 Census.\n",
    "\n",
    "# The Census Geocoder can associate ZCTAs with lat/long, which would be just the thing. But it allows only 1,000 \n",
    "# individual requests at a time. That would mean 14,700 separate batch jobs to apply ZCTA IDs to the 14.7 mn\n",
    "# InfoGroup records for 2017. That doesn't come close to scaling.\n",
    "\n",
    "# Python has a free zipcode database (installable with pip) called 'uszipcode'. It refers only to\n",
    "# postal zip codes. It does not take addresses as input but it does take lat/long, among many other parameters.\n",
    "# https://uszipcode.readthedocs.io/index.html#id8\n",
    "\n",
    "# Through the ZCTA relationship files we can associate ZCTAs with the OMB's \n",
    "# metropolitan/micropolitan/nonmetropolitan spatial units and draw a basemap of ZCTAs, but we don't have\n",
    "# analytical data at the moment at that geographical level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = 'data/FARcodesZIPdata2010WithAKandHI.csv'\n",
    "df = pd.read_csv(infile,dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ZIP'] = df['ZIP'].apply(lambda x: x.zfill(5) if len(x) < 5 == 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ZIP', 'state', 'name', 'far1', 'far2', 'far3', 'far4', 'gridpop',\n",
       "       'sqmi', 'density', 'fr1pop', 'fr2pop', 'fr3pop', 'fr4pop', 'fr1pct',\n",
       "       'fr2pct', 'fr3pct', 'fr4pct'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIP</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>far1</th>\n",
       "      <th>far2</th>\n",
       "      <th>far3</th>\n",
       "      <th>far4</th>\n",
       "      <th>gridpop</th>\n",
       "      <th>sqmi</th>\n",
       "      <th>density</th>\n",
       "      <th>fr1pop</th>\n",
       "      <th>fr2pop</th>\n",
       "      <th>fr3pop</th>\n",
       "      <th>fr4pop</th>\n",
       "      <th>fr1pct</th>\n",
       "      <th>fr2pct</th>\n",
       "      <th>fr3pct</th>\n",
       "      <th>fr4pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00002</td>\n",
       "      <td>AK</td>\n",
       "      <td>Yukon Flats Nat Wildlife</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>607</td>\n",
       "      <td>95,707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>606.4550106</td>\n",
       "      <td>606.4550106</td>\n",
       "      <td>606.4550106</td>\n",
       "      <td>606.4550106</td>\n",
       "      <td>99.96791067</td>\n",
       "      <td>99.96791067</td>\n",
       "      <td>99.96791067</td>\n",
       "      <td>99.96791067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>00007</td>\n",
       "      <td>AK</td>\n",
       "      <td>Southerly North Slope Bo</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>65,388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.6690849</td>\n",
       "      <td>81.6690849</td>\n",
       "      <td>81.6690849</td>\n",
       "      <td>81.6690849</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>99723</td>\n",
       "      <td>AK</td>\n",
       "      <td>Barrow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4,714</td>\n",
       "      <td>20,301</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4713.558186</td>\n",
       "      <td>4713.558186</td>\n",
       "      <td>4713.558186</td>\n",
       "      <td>682.6115643</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>14.48187414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>99559</td>\n",
       "      <td>AK</td>\n",
       "      <td>Bethel</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11,984</td>\n",
       "      <td>18,097</td>\n",
       "      <td>0.7</td>\n",
       "      <td>11983.63138</td>\n",
       "      <td>11983.63138</td>\n",
       "      <td>11983.63138</td>\n",
       "      <td>6710.332216</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>55.99581632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>99573</td>\n",
       "      <td>AK</td>\n",
       "      <td>Copper Center</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1,896</td>\n",
       "      <td>17,741</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1896.342902</td>\n",
       "      <td>1896.342902</td>\n",
       "      <td>1896.342902</td>\n",
       "      <td>1896.342902</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ZIP state                      name far1 far2 far3 far4 gridpop    sqmi  \\\n",
       "0  00002    AK  Yukon Flats Nat Wildlife    1    1    1    1     607  95,707   \n",
       "1  00007    AK  Southerly North Slope Bo    1    1    1    1      82  65,388   \n",
       "2  99723    AK                    Barrow    1    1    1    0   4,714  20,301   \n",
       "3  99559    AK                    Bethel    1    1    1    1  11,984  18,097   \n",
       "4  99573    AK             Copper Center    1    1    1    1   1,896  17,741   \n",
       "\n",
       "  density       fr1pop       fr2pop       fr3pop       fr4pop       fr1pct  \\\n",
       "0     0.0  606.4550106  606.4550106  606.4550106  606.4550106  99.96791067   \n",
       "1     0.0   81.6690849   81.6690849   81.6690849   81.6690849          100   \n",
       "2     0.2  4713.558186  4713.558186  4713.558186  682.6115643          100   \n",
       "3     0.7  11983.63138  11983.63138  11983.63138  6710.332216          100   \n",
       "4     0.1  1896.342902  1896.342902  1896.342902  1896.342902          100   \n",
       "\n",
       "        fr2pct       fr3pct       fr4pct  \n",
       "0  99.96791067  99.96791067  99.96791067  \n",
       "1          100          100          100  \n",
       "2          100          100  14.48187414  \n",
       "3          100          100  55.99581632  \n",
       "4          100          100          100  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('***',str(len(df)),'***')\n",
    "f1 = df[df['far1']=='1']\n",
    "print(len(f1))\n",
    "f2 = df[df['far2']=='1']\n",
    "print(len(f2))\n",
    "f3 = df[df['far3']=='1']\n",
    "print(len(f3))\n",
    "f4 = df[df['far4']=='1']\n",
    "print(len(f4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'FAR Level' variable: \n",
    "# 0 if all far* variables are zero.\n",
    "# 1 if far1==1 and all others 0.\n",
    "# 2 if far2==1 and far3==0 and far4==0\n",
    "# 3 if far3==1 and far4==0\n",
    "# 4 if far4==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zip = df[['ZIP','far1','far2','far3','far4']].copy()\n",
    "df_zip[['far1','far2','far3','far4']] = df_zip[['far1','far2','far3','far4']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def farlevel(row):\n",
    "    if sum([row['far1'],row['far2'],row['far3'],row['far4']]) == 0:\n",
    "        return 0\n",
    "    elif row['far1'] == 1 and sum([row['far2'],row['far3'],row['far4']]) == 0:\n",
    "        return 1\n",
    "    elif row['far2'] == 1 and sum([row['far3'],row['far4']]) == 0:\n",
    "        return 2\n",
    "    elif row['far3'] == 1 and row['far4'] == 0:\n",
    "        return 3\n",
    "    elif row['far4'] == 1:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zip['FAR Level'] = df_zip.apply(farlevel,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30337\n",
      "30319\n"
     ]
    }
   ],
   "source": [
    "print(len(df_zip))\n",
    "df_zip = df_zip.drop_duplicates()\n",
    "print(len(df_zip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24999\n",
       "4     2599\n",
       "1     1167\n",
       "2      967\n",
       "3      587\n",
       "Name: FAR Level, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zip['FAR Level'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "consistent_0 = df[(df['far1']=='0') & (df['far2']=='0') & (df['far3']=='0') & (df['far4']=='0')]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "consistent_1 = df[(df['far1']=='1') & (df['far2']=='1') & (df['far3']=='1') & (df['far4']=='1')]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(len(consistent_0))\n",
    "print(len(consistent_1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "consistent = pd.concat([consistent_0,consistent_1],ignore_index=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(consistent)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "merge_temp = df.merge(consistent,how='left',on='ZIP',indicator=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "merge_temp['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inconsistent = merge_temp[merge_temp['_merge']=='left_only'].drop(['state_y','name_y','far1_y', 'far2_y', 'far3_y', \n",
    "        'far4_y', 'gridpop_y', 'sqmi_y', 'density_y', 'fr1pop_y', 'fr2pop_y', 'fr3pop_y', 'fr4pop_y', 'fr1pct_y',\n",
    "        'fr2pct_y', 'fr3pct_y', 'fr4pct_y', '_merge'], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inconsistent.rename(index=str,columns={'state_x':'state','name_x':'name','far1_x':'far1','far2_x':'far2',\n",
    "                                      'far3_x':'far3','far4_x':'far4','gridpop_x':'gridpop','sqmi_x':'sqmi',\n",
    "                                      'density_x':'density','fr1pop_x':'fr1pop','fr2pop_x':'fr2pop',\n",
    "                                      'fr3pop_x':'fr3pop','fr4pop_x':'fr4pop','fr1pct_x':'fr1pct',\n",
    "                                      'fr2pct_x':'fr2pct','fr3pct_x':'fr3pct','fr4pct_x':'fr4pct'},inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(consistent.columns)\n",
    "print(inconsistent.columns)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Created a dataframe of inconsistent far codes to try to figure out what the meaning of them is. \n",
    "print(inconsistent.head())\n",
    "print(inconsistent.tail())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ========================================\n",
    "# Testing python's 'uszipcode' database."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# uszipcode has two backend database, SimpleZipcode and Zipcode. Zipcode has more info, but the database file \n",
    "# is 450MB (takes more time to download). SimpleZipcode doesn’t has all data points listed above, but the \n",
    "# database file is smaller (9MB). By default uszipcode uses SimpleZipcode. You can use this code to choose to \n",
    "# use the rich info Zipcode:\n",
    "\n",
    "#>>> from uszipcode import SearchEngine\n",
    "#>>> search = SearchEngine(simple_zipcode=False)\n",
    "\n",
    "from uszipcode import SearchEngine\n",
    "search = SearchEngine(simple_zipcode=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "result = search.by_zipcode('53589')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d = result.to_dict()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "search.query(lat=d['lat'],lng=d['lng'],radius=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14733437"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infile = 'data/df_2017_OMB_Census_HRSA.csv'\n",
    "df_ig = pd.read_csv(infile,dtype=object)\n",
    "len(df_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ig['ZipCode'] = df_ig['ZipCode'].apply(lambda x: x.zfill(5) if len(x) < 5 == 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 39s, sys: 21.1 s, total: 2min\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add FAR codes to each InfoGroup record by matching on zip codes\n",
    "df_out = df_ig.merge(df_zip,how='left',left_on='ZipCode',right_on='ZIP',indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "both          13265723\n",
       "left_only      1467714\n",
       "right_only           0\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.drop(columns=['ZIP','_merge'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14571195"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select records only for 48 continental states for reporting. (FAR codes apply only to them.)\n",
    "df_select = df_out[(df_out['Continental']=='1') & (df_out['State FIPS'] != '11')].copy()\n",
    "len(df_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 14571195 ***\n",
      "0.01518399829252165\n",
      "0.011140541321422162\n",
      "0.007552091643821938\n",
      "0.008008128365587036\n"
     ]
    }
   ],
   "source": [
    "f = len(df_select)\n",
    "print('***',str(f),'***')\n",
    "\n",
    "f1 = len(df_select[df_select['FAR Level'] == 1])\n",
    "print(f1/f)\n",
    "\n",
    "f2 = len(df_select[df_select['FAR Level'] == 2])\n",
    "print(f2/f)\n",
    "\n",
    "f3 = len(df_select[df_select['FAR Level'] == 3])\n",
    "print(f3/f)\n",
    "\n",
    "f4 = len(df_select[df_select['FAR Level'] == 4])\n",
    "print(f4/f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10019150797172093\n",
      "0.8998084920282791\n",
      "\n",
      "Stats only for in-scope (48 states) and non-missing.\n",
      "Not Far and remote: 0.9534514732919008\n",
      "Far and remote: 0.04654852670809917\n"
     ]
    }
   ],
   "source": [
    "fmiss = len(df_select[df_select['FAR Level'].isnull()])\n",
    "print(str(fmiss/f))\n",
    "\n",
    "fnum = len(df_select[df_select['FAR Level'] >= 0])\n",
    "print(str(fnum/f))\n",
    "\n",
    "print('\\n'+'Stats only for in-scope (48 states) and non-missing.')\n",
    "f0 = len(df_select[df_select['FAR Level'] == 0])\n",
    "print('Not Far and remote:',str(f0/fnum))\n",
    "\n",
    "ft = len(df_select[df_select['FAR Level'] >= 1])\n",
    "print('Far and remote:',str(ft/fnum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'data/df_2017_OMB_Census_HRSA_FAR.csv'\n",
    "df_out.to_csv(outfile,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
